{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental notebook on using Langchain\n",
    "\n",
    "### Covered experiments: \n",
    "1. OpenAI API call \n",
    "1. PyPDF2 file reading\n",
    "1. Prompt template\n",
    "1. Chain \n",
    "1. Agent\n",
    "1. Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9, max_tokens=3000)\n",
    "# name = llm.predict(\"t a fency name for this.\")\n",
    "# print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the resume PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_path = '/Users/yusali/Library/CloudStorage/OneDrive-UniversityofToronto/Yussaaa/JOB/Resume_Yusa Li_MLEngineer.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Yusa Li Toronto, ON, M4Y 0E8 | 780-707-7844 | yusa.li@mail.utoronto.ca | linkedin.com/in/yusa-li/ | github.com/yussaaa  Enthusiastic ML Engineer with experience in Canadian CPI production, 4+ years of experience on end-to-end ML projects such as NLP classification, named entity extraction, anomaly detection, ML pipeline orchestration and Azure cloud deployment HIGHLIGHTS and TECHNICAL SKILLS          • Self-starter with strong initiative in identifying and solving problems through research, development and testing • Advanced analytical skills developed through projects in areas of finance, retail, marketing using millions of rows dataset  • Analytics & Visualization: SQL · Tableau · Power BI · SparkSQL · BigQuery · Azure Synapse · Matplotlib · Seaborn · Plotly • Big Data & Cloud:                Spark · Databricks · Azure · AWS · GCP · Terraform  • Data Science tools:             PyTorch · TensorFlow · scikit-learn · Pandas · NumPy · Spacy · Label Studio · Great Expectations • Programming:                      Python · SQL (MySQL · PostgreSQL) · R · Linux/Bash · Git · Docker · JavaScript · React · Flask • Certification:                     Azure Data Scientist Associate (Since Sept 30, 2022) · AWS Solution Architect Associate (Exam scheduled) PROFESSIONAL EXPERIENCE  Statistic Canada – Consumer Price Division                                                                                                                                                                     Toronto                 Machine Learning Engineer                                                                                                                                                     Feb 2022 – May 2023 • Developed and deployed MLOps data validation pipeline on AzureML. Built data validation rules using Great Expectations  • Contributed to Great Expectations open-source community with custom expectation for null value check • Lead a multi-hop data transferring project. Developed a pipeline that ingested files with various format from the data landing bronze container and move files to pass/fail Sliver container based on the validation results. Automated with Azure Data Factory file trigger • Orchestrated the Classifier and the Outlier detection microservice using Luigi • Automated the time-consuming multi-step script running workflow into a bash script which reduced 90% of daily work effort Data Scientist                                                                                                                                                                          Dec 2020 – Feb 2022 • Developed Named Entity Recognition model for extracting electronics products features. Full ML cycle was practiced from data labeling (hosting Label Studio docker image on Azure App Service), concept validation to model building (Spacy) • Scrapped text description data using Beautiful Soup and selenium. Prototyped NER service with Azure cognitive service • Developed Outlier Detection methodology to ease the current full QA process • Built Amazon product historical price tracking tool using Keepa and Python. Visualized in PowerBI dashboard  BMO-Global Asset Management                                                                                                                                                                     Toronto                 Database Analyst                                                                                                                                                                   Mar 2020 – May 2020 • Automated portfolio reporting process by extracting and transforming from millions rows equity data using WebFOCUS  • Designed and executed testing plan to evaluate and ensure data quality using SQL, Excel functions, pivot tables, Power BI • Collaborated and supported the team remotely in the agile scrum-based project to fix issues in time  • Communicated with stakeholders to gather accurate requirements for the Business Intelligence report PROJECTS                                                                                              Full Stack Transfer learning food classifier                                                                                                                                  • Loaded pre-trained feature and fine-tune using Food101 dataset • Compared performance 30Mb EffnetB2 and 295Mb ViT-b-16 model. Opted EffnetB2 for production due to its size advantage • Built Gradio app with the trained model and deployed the app to Hugging Face Space Sentiment Analysis on Employee Review on Databricks                                                                                                                                           • Conducted NLP sentiment analysis on employee’s text reviews using PySpark  • Inspected the rating and review summary by investigating the aggregated statistical description of each company  • Calculated sentiment from text summary using TextBlob sentiment polarity method  • Built a MLlib pipeline and reached F1 score of 83% using a Random Forest model with TF-IDF vectorizer   EDUCATION  Master of Engineering, Industrial Engineering (Emphasis on Analytics / Data Science)                                                           2018 - 2019 University of Toronto                                    Bachelor of Science, Mechanical Engineering                                                                                                                                  2014 - 2018  University of Alberta  \n"
     ]
    }
   ],
   "source": [
    "# importing required modules\n",
    "import PyPDF2\n",
    " \n",
    "# creating a pdf file object\n",
    "pdfFileObj = open(PDF_path, 'rb')\n",
    " \n",
    "# creating a pdf reader object\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    " \n",
    "# printing number of pages in pdf file\n",
    "print(len(pdfReader.pages))\n",
    " \n",
    "# creating a page object\n",
    "pageObjb = pdfReader.pages[0]\n",
    "pdf_text = pageObj.extract_text()\n",
    "# extracting text from page\n",
    "print(pdf_text)\n",
    " \n",
    "# closing the pdf file object\n",
    "pdfFileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pdftotext preserves the formats from the PDF while PyPDF2 lost them and only returns the text\n",
    "\n",
    "import pdftotext\n",
    "# Load your PDF\n",
    "with open(PDF_path, \"rb\") as f:\n",
    "    pdf = pdftotext.PDF(f)\n",
    "# Read all the text into one string\n",
    "pdftotext_text = \"\\n\\n\".join(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompot Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_resume_fix = PromptTemplate(\n",
    "    input_variables =['resume'],\n",
    "    template = \"Help me fix the grammar issues in the following resume \\n {resume} \\n Bold any changes with ** around the text\"\n",
    ")\n",
    "p = prompt_template_resume_fix.format(resume=pdftotext_text)\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.predict(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4162"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['resume'], output_parser=None, partial_variables={}, template='Help me fix the grammar issues in the following resume \\n {resume} \\n Bold any changes with ** around the text', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_resume_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m LLMChain\n\u001b[1;32m      3\u001b[0m \u001b[39m# Simple chain\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39;49mllm, prompt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhello\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m response \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39mrun(pdftotext_text)\n",
      "File \u001b[0;32m~/dev/job-hunt-LLM-Helper/venv/lib/python3.10/site-packages/langchain/load/serializable.py:75\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/dev/job-hunt-LLM-Helper/venv/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Simple chain\n",
    "chain = LLMChain(llm=llm, prompt=)\n",
    "response = chain.run(pdftotext_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nYusa Li\\nToronto, ON, M4Y 0E8 | 780-707-7844 | yusa.li@mail.utoronto.ca | linkedin.com/in/yusa-li/ | github.com/yussaaa\\nEnthusiastic ML Engineer with experience in Canadian CPI production, 4+ years of experience on end-to-end ML projects such as NLP classification, named entity extraction, anomaly detection, ML pipeline orchestration and Azure cloud deployment\\nHIGHLIGHTS and TECHNICAL SKILLS\\n• Self-starter with strong initiative in identifying and solving problems through research, development, and testing\\n• Advanced analytical skills developed through projects in areas of finance, retail, and marketing using millions of rows of data\\n• Analytics & Visualization: SQL, Tableau, Power BI, SparkSQL, BigQuery, Azure Synapse, Matplotlib, Seaborn, Plotly\\n• Big Data & Cloud: Spark, Databricks, Azure, AWS, GCP, Terraform\\n• Data Science tools: PyTorch, TensorFlow, scikit-learn, Pandas, NumPy, Spacy, Label Studio, Great Expectations\\n• Programming: Python'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Simple chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_resume_fix)\n",
    "chain.run(pdftotext_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Chinese',\n",
       " 'restaurant_name': '\\n\\nDragon Palace',\n",
       " 'menu_items': '\\n\\n-Stir-Fried Prawns with Garlic and Chili\\n-Honey-Glazed Barbecued Pork\\n-Crispy Duck with Hoisin Sauce\\n-Wok-Fried Beef with Oyster Sauce\\n-Spicy Kung Pao Chicken\\n-Szechuan-Style Vegetable Medley\\n-Cantonese-Style Chow Mein\\n-Egg Fried Rice\\n-Vegetable Spring Rolls\\n-Hot and Sour Soup\\n-Mango Pudding'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\": \"Chinese\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.load_tools import get_all_tool_names\n",
    "\n",
    "get_all_tool_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the GDP of US in 2022\n",
      "Action: Search\n",
      "Action Input: US GDP in 2022\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m$25.46 trillion\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to add 5 to this number\n",
      "Action: Calculator\n",
      "Action Input: 25.46 + 5\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 30.46\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The GDP of US in 2022 plus 5 is $30.46 trillion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The GDP of US in 2022 plus 5 is $30.46 trillion.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Let's test it out!\n",
    "agent.run(\"What was the GDP of US in 2022 plus 5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Elon Musk was born and then calculate his age.\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a business magnate and investor. Musk is the founder, chairman, CEO and chief technology officer of SpaceX;  angel investor, CEO, product architect and former chairman of Tesla, Inc.; owner, chairman and CTO of X Corp.; founder of the Boring Company; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is the wealthiest person in the world, with an estimated net worth of US$226 billion as of September 2023, according to the Bloomberg Billionaires Index, and $249 billion according to Forbes, primarily from his ownership stakes in both Tesla and SpaceX.Musk was born in Pretoria, South Africa, and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University in Kingston, Ontario. Musk later transferred to the University of Pennsylvania, and received bachelor's degrees in economics and physics there. He moved to California in 1995 to attend Stanford University. However, Musk dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999, and with $12 million of the money he made, that same year Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal. \n",
      "In 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2022, he acquired Twitter for $44 billion and subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, he founded xAI, an artificial-intelligence company.\n",
      "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including that of spreading COVID-19 misinformation, and promoting conspiracy theories. His Twitter ownership has been similarly controversial, including laying off a large number of employees, an increase in hate speech on the platform and features such as Twitter Blue and the implementation of limits on the amount of viewable Tweets per day being criticized. In 2018, the U.S. Securities and Exchange Commission (SEC) sued him for falsely tweeting that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine.\n",
      "\n",
      "Page: Acquisition of Twitter by Elon Musk\n",
      "Summary: Business magnate Elon Musk initiated an acquisition of American social media company Twitter, Inc. on April 14, 2022, and concluded it on October 27, 2022. Musk had begun buying shares of the company in January 2022, becoming its largest shareholder by April with a 9.1 percent ownership stake. Twitter invited Musk to join its board of directors, an offer he initially accepted before declining. On April 14, Musk made an unsolicited offer to purchase the company, to which Twitter's board initially responded with a \"poison pill\" strategy to resist a hostile takeover, before unanimously accepting Musk's buyout offer of $44 billion on April 25. Musk stated that he planned to introduce new features to the platform, make its algorithms open-\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate Elon Musk's age in 2023.\n",
      "Action: Calculator\n",
      "Action Input: (2023 - 1971)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 52\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Elon Musk was born in 1971 and is 52 years old in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk was born in 1971 and is 52 years old in 2023.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install this package: pip install wikipedia\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Let's test it out!\n",
    "agent.run(\"When was Elon musk born? What is his age right now in 2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "https://python.langchain.com/docs/modules/memory/\n",
    "\n",
    "#### Note: \n",
    "Be careful with the memory setting. All the history will be passed to the API called and incur cost. \n",
    "\n",
    "Could use ConversationBufferWindowMemory with small k to limit the size of the history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=3)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 10.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I don't know the answer to that question.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who was the captain of the winning team?\n",
      "AI:  I'm sorry, I don't know the answer to that question.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse job posting from LinkedIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt using only BS4, failed due to the Show More button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.linkedin.com/jobs/view/3664919987\"\n",
    "\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Engineer - Contract'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wave HQ'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a', class_='topcard__org-name-link topcard__flavor--black-link').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toronto, Ontario, Canada'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('span', class_='topcard__flavor topcard__flavor--bullet').text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 month ago'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('span', class_='posted-time-ago__text topcard__flavor--metadata').text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', class_='show-more-less-html__markup relative overflow-hidden')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need selenium to click the \"Show More\" button to reveal the full job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_job_url = 'https://www.linkedin.com/jobs/view/3664919987'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeautifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m driver\u001b[39m.\u001b[39mexecute_script(\u001b[39m\"\u001b[39m\u001b[39marguments[0].click();\u001b[39m\u001b[39m\"\u001b[39m, show_more_button)\n\u001b[1;32m     11\u001b[0m updated_html \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source\n\u001b[0;32m---> 13\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(updated_html, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m driver\u001b[39m.\u001b[39mquit()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BeautifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.linkedin.com/jobs/view/3664919987\")\n",
    "\n",
    "show_more_button = driver.find_element(By.CLASS_NAME, \"show-more-less-html__button\")\n",
    "driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "\n",
    "updated_html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(updated_html, \"html.parser\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Engineer - Contract'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = soup.find('h1').text\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wave HQ'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = soup.find('a', class_='topcard__org-name-link topcard__flavor--black-link').text.strip()\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toronto, Ontario, Canada'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location = soup.find('span', class_='topcard__flavor topcard__flavor--bullet').text.strip()\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 month ago'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posted_time = soup.find('span', class_='posted-time-ago__text topcard__flavor--metadata').text.strip()\n",
    "posted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We believe small businesses are at the heart of our communities, and championing them is worth fighting for. We empower small business owners to manage their finances fearlessly, by offering the simplest, all-in-one financial management solution they can't live without.About The RoleWe are looking for a Machine Learning Engineer who will strengthen our capacity to improve the scalability, maintainability and adaptability of our ML practice. This individual will be part of the ML team and report to the Director of Data.The ML team is responsible for developing machine learning models as point solutions for our functional and product stakeholders within the business. We leverage MLOps to accelerate and systematize model development and the management of machine learning infrastructure.Machine Learning is part of Wave’s wider Data function, and works closely with Data Engineers, Analytic Engineers, and Data Analysts who comprise the Analytics and Data Operations and Platform groups. Our collective strength as a Data Team comes from our relationships and close collaboration, enabling us to drive strategic and operational decision-making, and to advocate the data vision at Wave.Here’s how you will make a differenceWork closely within an Agile team of fellow ML Engineers and collaborate with Wave stakeholder teams to build and deploy models that address business objectives, solve complex problems, and simplify the lives of our small business customersApply your expertise to analyze and engineer features using vast amounts of data from multiple sources. Train and deploy models in production, monitor them for quality and adapt them as the data and business contexts evolveAutomate and maintain a system architecture that supports machine learning in processing more features, training and deploying more models, and observing batch and real time inference at scaleThis is what you need to succeedYou have 3+ years of hands-on experience implementing and maintaining production machine learning systemsYou possess a strong foundational knowledge in machine learning, and have trained and tuned a range of classification models using algorithms such as decision trees, gradient boosting, naive bayes, SVMsYou’re extremely comfortable with Python and SQL, and very familiar with AWS, Amazon SageMaker and Docker. Our stack includes SageMaker pipelines, Model Registry, AWS CodePipeline, Step Functions, CircleCI, S3, Redshift, Looker, as well as MLflow, DataDog, StreamLit for monitoring and performance checkingYou have practical knowledge of MLOps and can build pipelines that train, tune and deploy models triggered by code changes, model degradation, and statistical driftPractical knowledge and experience with natural language processing, large language models, vector databases and LLM frameworks like LangChain are a bonusYou’ll thrive here ifYou’re self-motivated and have the ability to work autonomously. We count on you to get your work done, in ambiguous conditions, with tight deadlines, while still producing high-quality work. It’s fun, we promise!You are all about collaboration. You’ll be working within ML and Data, and with different teams across Wave. It’s not going to work if you don’t see the value of different perspectivesYou are a stellar communicator. This means you know how to translate technical terms into non-technical language that is easy to understandAt Wave, you’re treated like the incredible human being you are.Work From Where You Work Best: We will always have a welcoming, energizing, and world-class office (in Toronto) with a space for you. Or, if you’re more comfortable working from home, the choice is yours.We Care About Future You: You will stretch yourself and you will grow at Wave. You will also be supported on this journey with diverse learning experiences, educational allowances, mentorship, and so much more.We Support the Full You: We make a serious investment in your health & wellness. When we think about benefits we think about body, mind, & soul and we take this stuff very seriously.We Take Care of the Fundamentals: Fair compensation, all the office perks you’d want, and the various goodies you’d expect from a growing tech company. This is the obvious stuff, but we don’t want you to think we forgot!We believe that a diverse and inclusive culture creates the best workplace. We embrace our differences, value individuality, and the broad spectrum of every Waver's skills and abilities. We challenge each other from a place of respect and pursuit of continuous growth. We trust each other and encourage everyone to bring their authentic selves to work, everyday. As Wavers, our voices matter, our opinions are met with an open mind. The best ideas win, no matter whose they are. Contributing to an inclusive culture is a part of all of our job descriptions.We’ve been continuously recognized as one of Canada's Top Ten Most Admired Corporate Cultures and one of Canada’s Great Places to Work in categories including Technology, Millennials, Mental Health, Inclusion and Women.Are you ready to be a Waver? Join us!\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description = soup.find('div', class_='show-more-less-html__markup relative overflow-hidden').text.strip()\n",
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = [job_name, company_name, job_location, posted_time, job_description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Machine Learning Engineer - Contract; Wave HQ; Toronto, Ontario, Canada; 1 month ago; We believe small businesses are at the heart of our communities, and championing them is worth fighting for. We empower small business owners to manage their finances fearlessly, by offering the simplest, all-in-one financial management solution they can't live without.About The RoleWe are looking for a Machine Learning Engineer who will strengthen our capacity to improve the scalability, maintainability and adaptability of our ML practice. This individual will be part of the ML team and report to the Director of Data.The ML team is responsible for developing machine learning models as point solutions for our functional and product stakeholders within the business. We leverage MLOps to accelerate and systematize model development and the management of machine learning infrastructure.Machine Learning is part of Wave’s wider Data function, and works closely with Data Engineers, Analytic Engineers, and Data Analysts who comprise the Analytics and Data Operations and Platform groups. Our collective strength as a Data Team comes from our relationships and close collaboration, enabling us to drive strategic and operational decision-making, and to advocate the data vision at Wave.Here’s how you will make a differenceWork closely within an Agile team of fellow ML Engineers and collaborate with Wave stakeholder teams to build and deploy models that address business objectives, solve complex problems, and simplify the lives of our small business customersApply your expertise to analyze and engineer features using vast amounts of data from multiple sources. Train and deploy models in production, monitor them for quality and adapt them as the data and business contexts evolveAutomate and maintain a system architecture that supports machine learning in processing more features, training and deploying more models, and observing batch and real time inference at scaleThis is what you need to succeedYou have 3+ years of hands-on experience implementing and maintaining production machine learning systemsYou possess a strong foundational knowledge in machine learning, and have trained and tuned a range of classification models using algorithms such as decision trees, gradient boosting, naive bayes, SVMsYou’re extremely comfortable with Python and SQL, and very familiar with AWS, Amazon SageMaker and Docker. Our stack includes SageMaker pipelines, Model Registry, AWS CodePipeline, Step Functions, CircleCI, S3, Redshift, Looker, as well as MLflow, DataDog, StreamLit for monitoring and performance checkingYou have practical knowledge of MLOps and can build pipelines that train, tune and deploy models triggered by code changes, model degradation, and statistical driftPractical knowledge and experience with natural language processing, large language models, vector databases and LLM frameworks like LangChain are a bonusYou’ll thrive here ifYou’re self-motivated and have the ability to work autonomously. We count on you to get your work done, in ambiguous conditions, with tight deadlines, while still producing high-quality work. It’s fun, we promise!You are all about collaboration. You’ll be working within ML and Data, and with different teams across Wave. It’s not going to work if you don’t see the value of different perspectivesYou are a stellar communicator. This means you know how to translate technical terms into non-technical language that is easy to understandAt Wave, you’re treated like the incredible human being you are.Work From Where You Work Best: We will always have a welcoming, energizing, and world-class office (in Toronto) with a space for you. Or, if you’re more comfortable working from home, the choice is yours.We Care About Future You: You will stretch yourself and you will grow at Wave. You will also be supported on this journey with diverse learning experiences, educational allowances, mentorship, and so much more.We Support the Full You: We make a serious investment in your health & wellness. When we think about benefits we think about body, mind, & soul and we take this stuff very seriously.We Take Care of the Fundamentals: Fair compensation, all the office perks you’d want, and the various goodies you’d expect from a growing tech company. This is the obvious stuff, but we don’t want you to think we forgot!We believe that a diverse and inclusive culture creates the best workplace. We embrace our differences, value individuality, and the broad spectrum of every Waver's skills and abilities. We challenge each other from a place of respect and pursuit of continuous growth. We trust each other and encourage everyone to bring their authentic selves to work, everyday. As Wavers, our voices matter, our opinions are met with an open mind. The best ideas win, no matter whose they are. Contributing to an inclusive culture is a part of all of our job descriptions.We’ve been continuously recognized as one of Canada's Top Ten Most Admired Corporate Cultures and one of Canada’s Great Places to Work in categories including Technology, Millennials, Mental Health, Inclusion and Women.Are you ready to be a Waver? Join us!\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'; '.join(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'Job Name': job_name, \n",
    "            'Company Name': company_name, \n",
    "            'Job Location': job_location, \n",
    "            'Posted Time': posted_time, \n",
    "            'Job Description': job_description}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descp = info_dict['Job Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_JD_summary = PromptTemplate(\n",
    "    input_variables =['jd'],\n",
    "    template = \"Summarize the following Job description into two parts. 1. What this role need to do 2. What skills does this role require 3. Benefits of working in this company \\\n",
    "                Each part should have 5 bullet points, shorten the bullet points into keywords only, and make sure to include all the technologies. Make sure all the tools and tech mentioned are covered \\\n",
    "                Output to be in markdown format, with bold part tile, bullet point name \\n\\n \\\n",
    "                {jd}\"\n",
    ")\n",
    "p = prompt_template_JD_summary.format(jd=job_descp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_JD_summary = PromptTemplate(\n",
    "    input_variables =['jd'],\n",
    "    template = \"Summarize the following Job description into two parts. 1. What this role need to do 2. What skills does this role require 3. Benefits of working in this company \\\n",
    "                In the end of each part, put 2 new lines\\\n",
    "                Each part should have 5 bullet points, shorten the bullet points into keywords only, and make sure to include all the technologies. Make sure all the tools and tech mentioned are covered \\\n",
    "                Output to be in markdown format, with bold part tile, bullet point name \\n\\n \\\n",
    "                {jd}\"\n",
    ")\n",
    "p = prompt_template_JD_summary.format(jd=job_descp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_summary = llm.predict(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**What this role need to do**\\n- Analyze & engineer features\\n- Train & deploy models\\n- Maintain machine learning sys.\\n- Automate system architectures\\n- Build & deploy ML models',\n",
       " '**What skills does this role require**\\n- 3+yrs exp. ML sys.\\n- ML Algorithms:DT,GB,NB,SVM\\n- Python & SQL\\n- AWS, SageMaker, Docker\\n- MLOps, NLP, LLM, LLM Frameworks',\n",
       " '**Benefits of working in this company**\\n- Diverse & Inclusive Culture\\n- Work from Where You Work Best\\n- Investment in Health & Wellness\\n- Learning Experiences & Education\\n- Fair Compensation & Perks']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_summary.strip().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backend helper function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.linkedin_jd_parser import linkedin_jd_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_test = linkedin_jd_parser(test_job_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We believe small businesses are at the heart of our communities, and championing them is worth fighting for. We empower small business owners to manage their finances fearlessly, by offering the simplest, all-in-one financial management solution they can't live without.About The RoleWe are looking for a Machine Learning Engineer who will strengthen our capacity to improve the scalability, maintainability and adaptability of our ML practice. This individual will be part of the ML team and report to the Director of Data.The ML team is responsible for developing machine learning models as point solutions for our functional and product stakeholders within the business. We leverage MLOps to accelerate and systematize model development and the management of machine learning infrastructure.Machine Learning is part of Wave’s wider Data function, and works closely with Data Engineers, Analytic Engineers, and Data Analysts who comprise the Analytics and Data Operations and Platform groups. Our collective strength as a Data Team comes from our relationships and close collaboration, enabling us to drive strategic and operational decision-making, and to advocate the data vision at Wave.Here’s how you will make a differenceWork closely within an Agile team of fellow ML Engineers and collaborate with Wave stakeholder teams to build and deploy models that address business objectives, solve complex problems, and simplify the lives of our small business customersApply your expertise to analyze and engineer features using vast amounts of data from multiple sources. Train and deploy models in production, monitor them for quality and adapt them as the data and business contexts evolveAutomate and maintain a system architecture that supports machine learning in processing more features, training and deploying more models, and observing batch and real time inference at scaleThis is what you need to succeedYou have 3+ years of hands-on experience implementing and maintaining production machine learning systemsYou possess a strong foundational knowledge in machine learning, and have trained and tuned a range of classification models using algorithms such as decision trees, gradient boosting, naive bayes, SVMsYou’re extremely comfortable with Python and SQL, and very familiar with AWS, Amazon SageMaker and Docker. Our stack includes SageMaker pipelines, Model Registry, AWS CodePipeline, Step Functions, CircleCI, S3, Redshift, Looker, as well as MLflow, DataDog, StreamLit for monitoring and performance checkingYou have practical knowledge of MLOps and can build pipelines that train, tune and deploy models triggered by code changes, model degradation, and statistical driftPractical knowledge and experience with natural language processing, large language models, vector databases and LLM frameworks like LangChain are a bonusYou’ll thrive here ifYou’re self-motivated and have the ability to work autonomously. We count on you to get your work done, in ambiguous conditions, with tight deadlines, while still producing high-quality work. It’s fun, we promise!You are all about collaboration. You’ll be working within ML and Data, and with different teams across Wave. It’s not going to work if you don’t see the value of different perspectivesYou are a stellar communicator. This means you know how to translate technical terms into non-technical language that is easy to understandAt Wave, you’re treated like the incredible human being you are.Work From Where You Work Best: We will always have a welcoming, energizing, and world-class office (in Toronto) with a space for you. Or, if you’re more comfortable working from home, the choice is yours.We Care About Future You: You will stretch yourself and you will grow at Wave. You will also be supported on this journey with diverse learning experiences, educational allowances, mentorship, and so much more.We Support the Full You: We make a serious investment in your health & wellness. When we think about benefits we think about body, mind, & soul and we take this stuff very seriously.We Take Care of the Fundamentals: Fair compensation, all the office perks you’d want, and the various goodies you’d expect from a growing tech company. This is the obvious stuff, but we don’t want you to think we forgot!We believe that a diverse and inclusive culture creates the best workplace. We embrace our differences, value individuality, and the broad spectrum of every Waver's skills and abilities. We challenge each other from a place of respect and pursuit of continuous growth. We trust each other and encourage everyone to bring their authentic selves to work, everyday. As Wavers, our voices matter, our opinions are met with an open mind. The best ideas win, no matter whose they are. Contributing to an inclusive culture is a part of all of our job descriptions.We’ve been continuously recognized as one of Canada's Top Ten Most Admired Corporate Cultures and one of Canada’s Great Places to Work in categories including Technology, Millennials, Mental Health, Inclusion and Women.Are you ready to be a Waver? Join us!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_test['Job Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on the useage between ChatOpenAI and OpenAI API\n",
    "\n",
    "The LLM OpenAI API is more like a general language model to predict the next word. It had hard time to understand the prompt instructions. It only make prediction based on the given words. \n",
    "\n",
    "Whild the ChatOpenAI API is the same as th ChatGPT service is using. The instructions could be easily understood. Thus, in this use case, ChatOpenAI API should be used instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.langchain_helper import summarize_job_description, resume_jd_skill_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_summary = summarize_job_description(job_test['Job Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_summary_test = llm.predict(f\"Summarize the following Job description {job_test['Job Description']} into three parts. 1. What this role need to do 2. What skills does this role require 3. Benefits of working in this company \\\n",
    "                Each part should have 5 bullet points, shorten the bullet points into keywords only, and make sure to include all the technologies. Make sure all the tools and tech mentioned are covered \\\n",
    "                Output to be in markdown format, with bold part tile, bullet point name \\n\\n \\\n",
    "                \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Role Responsibilities:**\n",
      "\n",
      "- Strengthen ML practice scalability, maintainability, and adaptability\n",
      "- Develop machine learning models for functional and product stakeholders\n",
      "- Leverage MLOps for model development and management\n",
      "- Collaborate with Agile team and Wave stakeholder teams\n",
      "- Automate and maintain system architecture for machine learning\n",
      "\n",
      "**Required Skills:**\n",
      "\n",
      "- 3+ years of experience in production machine learning systems\n",
      "- Strong foundational knowledge in machine learning\n",
      "- Proficiency in Python, SQL, AWS, Amazon SageMaker, and Docker\n",
      "- Practical knowledge of MLOps and building pipelines\n",
      "- Bonus: experience with natural language processing and LLM frameworks\n",
      "\n",
      "**Benefits of Working at Wave:**\n",
      "\n",
      "- Flexible work location (office or remote)\n",
      "- Support for personal growth and learning\n",
      "- Investment in health and wellness\n",
      "- Competitive compensation and office perks\n",
      "- Inclusive and diverse company culture\n"
     ]
    }
   ],
   "source": [
    "print(jd_summary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_JD_summary = PromptTemplate(\n",
    "    input_variables =['jd'],\n",
    "    template = \"Summarize the following Job description {jd} into three parts. 1. What this role need to do 2. What skills does this role require 3. Benefits of working in this company \\\n",
    "                Each part should have 5 bullet points, shorten the bullet points into keywords only, and make sure to include all the technologies. Make sure all the tools and tech mentioned are covered \\\n",
    "                Output to be in markdown format, with bold part tile, bullet point name \\n\\n \\\n",
    "                \"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_JD_summary)\n",
    "\n",
    "response = name_chain.run(prompt_template_JD_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**1. What this role need to do**\n",
      "* Develop innovative solutions with Cloud technologies\n",
      "* Build and maintain microservices\n",
      "* Design and implement scalable systems\n",
      "* Deploy and maintain applications\n",
      "* Troubleshoot and debug systems\n",
      "\n",
      "**2. What skills does this role require**\n",
      "* Expertise in Cloud technologies\n",
      "* Knowledge of microservices\n",
      "* Experience with various programming languages\n",
      "* Proficiency in database management\n",
      "* Ability to manage large scale systems\n",
      "\n",
      "**3. Benefits of working in this company**\n",
      "* Competitive salary and benefits\n",
      "* Opportunity to work with cutting-edge technologies\n",
      "* Exposure to software engineering best practices\n",
      "* Flexible working hours and remote work\n",
      "* Opportunity to learn and grow\n"
     ]
    }
   ],
   "source": [
    "print(jd_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_required = jd_summary.strip().split('\\n\\n')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.langchain_helper import resume_jd_skill_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.0, max_tokens=3000)\n",
    "\n",
    "def resume_jd_skill_match(resume, job_skills):\n",
    "\n",
    "    prompt_template_JD_summary = PromptTemplate(\n",
    "    input_variables = ['resume','job_skills'],\n",
    "    template = \"Compare and show the skills listed in {job_skills}\\\n",
    "                are 1. Fully matched \\\n",
    "                    2. Partial matched \\\n",
    "                    3. Not matched \\\n",
    "                with the skills in {resume}\"\n",
    ")\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template_JD_summary)\n",
    "\n",
    "    response = chain.run({\"resume\": resume, \n",
    "                          \"job_skills\": job_skills})\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_match = resume_jd_skill_match2(pdftotext_text, skills_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Develop: React, Node.js, MongoDB, GraphQL\n",
      "- Design: UI/UX\n",
      "- Maintain: Database\n",
      "- Integrate: 3rd-Party APIs\n",
      "- Troubleshoot: Bugs\n"
     ]
    }
   ],
   "source": [
    "print(skills_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Fully matched: Design: UI/UX, Integrate: 3rd-Party APIs, Troubleshoot: Bugs\n",
      "2. Partial matched: Develop: React, Node.js, MongoDB, GraphQL, Maintain: Database\n",
      "3. Not matched: Machine Learning Engineer, Analytics & Visualization, Big Data & Cloud, Data Science tools, Programming, Certification, Self-starter, Advanced analytical skills, NLP classification, Named entity extraction, Anomaly detection, ML pipeline orchestration, Azure cloud deployment, SQL, Tableau, Power BI, SparkSQL, BigQuery, Azure Synapse, Matplotlib, Seaborn, Plotly, Spark, Databricks, Azure, AWS, GCP, Terraform, PyTorch, TensorFlow, scikit-learn, Pandas, NumPy, Spacy, Label Studio, Great Expectations, Python, R, Linux/Bash, Git, Docker, JavaScript, Flask, Azure Data Scientist Associate, AWS Solution Architect Associate, Data Validation Pipeline, Multi-hop data transferring project, Named Entity Recognition, Outlier Detection, Amazon product historical price tracking tool, Keepa, WebFOCUS, Testing Plan, Business Intelligence report, Full Stack Transfer learning food classifier, Sentiment Analysis, NLP Sentiment Analysis, MLlib Pipeline, F1 Score.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.0, max_tokens=3000)\n",
    "\n",
    "prompt_template_JD_summary = PromptTemplate(\n",
    "    input_variables = ['resume','job_skills'],\n",
    "    template = \"Compare and show the skills listed in {job_skills}\\\n",
    "                are 1. Fully matched \\\n",
    "                    2. Partial matched \\\n",
    "                    3. Not matched \\\n",
    "                with the skills in {resume}\"\n",
    ")\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template_JD_summary)\n",
    "\n",
    "    response = chain.run({\"resume\": resume, \n",
    "                          \"job_skills\": job_skills})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the chat backend API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.langchain_helper_chatapi import summarize_job_description, resume_jd_skill_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.3)\n",
    "\n",
    "def summarize_job_description(jd):\n",
    "    \"\"\"_summary____\n",
    "\n",
    "    Args:\n",
    "        jd (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # prompt_template_JD_summary = PromptTemplate(\n",
    "    # input_variables =['jd'],\n",
    "    template = \"Summarize the following Job description {jd} into three parts. 1. What this role need to do 2. What skills does this role require 3. Benefits of working in this company \\\n",
    "                Each part should have 5 bullet points, shorten the bullet points into keywords only, and make sure to include all the technologies. Make sure all the tools and tech mentioned are covered \\\n",
    "                Output to be in markdown format, with bold part tile, bullet point name \\n\\n \\\n",
    "                \"\n",
    "# )\n",
    "\n",
    "    # name_chain = LLMChain(llm=llm, prompt=prompt_template_JD_summary)\n",
    "\n",
    "    # response = name_chain.run(prompt_template_JD_summary)\n",
    "    response = llm.predict(template)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.2, max_tokens=3000)\n",
    "template = \"Summarize and extract information from the job description {jd} into three parts. 1. What this role need to do 2. What skills does this role require 3. Benefits of working in this company \\\n",
    "                Each part should have 5 bullet points, shorten the bullet points into keywords only, and make sure to include all the technologies. Make sure all the tools and technologies mentioned are in the output \\\n",
    "                Output to be in markdown format, with bold part tile, bullet point name \\n\\n \\\n",
    "                \"\n",
    "response = llm.call_as_llm(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_sum_2 = summarize_job_description(job_test['Job Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. What this role needs to do:**\n",
      "\n",
      "- Develop and maintain software applications and systems\n",
      "- Collaborate with cross-functional teams to gather requirements and design solutions\n",
      "- Conduct code reviews and ensure adherence to coding standards\n",
      "- Troubleshoot and debug software issues\n",
      "- Implement and maintain software documentation\n",
      "\n",
      "**2. Skills required for this role:**\n",
      "\n",
      "- Proficiency in programming languages such as Java, Python, and C++\n",
      "- Experience with web development frameworks like Angular and React\n",
      "- Knowledge of database management systems such as MySQL and MongoDB\n",
      "- Familiarity with version control systems like Git\n",
      "- Strong problem-solving and analytical skills\n",
      "\n",
      "**3. Benefits of working in this company:**\n",
      "\n",
      "- Competitive salary and benefits package\n",
      "- Opportunities for professional growth and career advancement\n",
      "- Collaborative and inclusive work environment\n",
      "- Cutting-edge technologies and tools\n",
      "- Work-life balance initiatives\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChatOpenAI' object has no attribute 'memory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm\u001b[39m.\u001b[39;49mmemory\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatOpenAI' object has no attribute 'memory'"
     ]
    }
   ],
   "source": [
    "llm.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. What this role need to do:**\n",
      "\n",
      "- Develop and maintain software applications\n",
      "- Collaborate with cross-functional teams to gather requirements and design solutions\n",
      "- Write clean, efficient, and scalable code\n",
      "- Conduct unit testing and debugging of applications\n",
      "- Stay updated with emerging technologies and industry trends\n",
      "\n",
      "**2. What skills does this role require:**\n",
      "\n",
      "- Proficiency in programming languages such as Java, Python, and C++\n",
      "- Experience with web development frameworks like React and Angular\n",
      "- Strong knowledge of database management systems, such as MySQL and MongoDB\n",
      "- Familiarity with version control systems like Git\n",
      "- Excellent problem-solving and analytical skills\n",
      "\n",
      "**3. Benefits of working in this company:**\n",
      "\n",
      "- Competitive salary and benefits package\n",
      "- Opportunities for career growth and professional development\n",
      "- Collaborative and inclusive work environment\n",
      "- Cutting-edge technologies and tools\n",
      "- Work-life balance and flexible work arrangements\n"
     ]
    }
   ],
   "source": [
    "print(js_sum_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. What this role need to do:**\n",
      "\n",
      "- Develop and maintain software applications\n",
      "- Collaborate with cross-functional teams to gather requirements and design solutions\n",
      "- Write clean, efficient, and maintainable code\n",
      "- Conduct unit testing and debugging of applications\n",
      "- Stay up-to-date with industry trends and technologies\n",
      "\n",
      "**2. What skills does this role require:**\n",
      "\n",
      "- Strong proficiency in programming languages such as Java, Python, and C++\n",
      "- Experience with web development frameworks like Angular and React\n",
      "- Knowledge of database management systems such as MySQL and MongoDB\n",
      "- Familiarity with version control systems like Git\n",
      "- Understanding of software development methodologies and best practices\n",
      "\n",
      "**3. Benefits of working in this company:**\n",
      "\n",
      "- Competitive salary and benefits package\n",
      "- Opportunities for professional growth and career advancement\n",
      "- Collaborative and inclusive work environment\n",
      "- Cutting-edge technologies and tools\n",
      "- Work-life balance and flexible work arrangements\n"
     ]
    }
   ],
   "source": [
    "print(js_sum_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We believe small businesses are at the heart of our communities, and championing them is worth fighting for. We empower small business owners to manage their finances fearlessly, by offering the simplest, all-in-one financial management solution they can't live without.About The RoleWe are looking for a Machine Learning Engineer who will strengthen our capacity to improve the scalability, maintainability and adaptability of our ML practice. This individual will be part of the ML team and report to the Director of Data.The ML team is responsible for developing machine learning models as point solutions for our functional and product stakeholders within the business. We leverage MLOps to accelerate and systematize model development and the management of machine learning infrastructure.Machine Learning is part of Wave’s wider Data function, and works closely with Data Engineers, Analytic Engineers, and Data Analysts who comprise the Analytics and Data Operations and Platform groups. Our collective strength as a Data Team comes from our relationships and close collaboration, enabling us to drive strategic and operational decision-making, and to advocate the data vision at Wave.Here’s how you will make a differenceWork closely within an Agile team of fellow ML Engineers and collaborate with Wave stakeholder teams to build and deploy models that address business objectives, solve complex problems, and simplify the lives of our small business customersApply your expertise to analyze and engineer features using vast amounts of data from multiple sources. Train and deploy models in production, monitor them for quality and adapt them as the data and business contexts evolveAutomate and maintain a system architecture that supports machine learning in processing more features, training and deploying more models, and observing batch and real time inference at scaleThis is what you need to succeedYou have 3+ years of hands-on experience implementing and maintaining production machine learning systemsYou possess a strong foundational knowledge in machine learning, and have trained and tuned a range of classification models using algorithms such as decision trees, gradient boosting, naive bayes, SVMsYou’re extremely comfortable with Python and SQL, and very familiar with AWS, Amazon SageMaker and Docker. Our stack includes SageMaker pipelines, Model Registry, AWS CodePipeline, Step Functions, CircleCI, S3, Redshift, Looker, as well as MLflow, DataDog, StreamLit for monitoring and performance checkingYou have practical knowledge of MLOps and can build pipelines that train, tune and deploy models triggered by code changes, model degradation, and statistical driftPractical knowledge and experience with natural language processing, large language models, vector databases and LLM frameworks like LangChain are a bonusYou’ll thrive here ifYou’re self-motivated and have the ability to work autonomously. We count on you to get your work done, in ambiguous conditions, with tight deadlines, while still producing high-quality work. It’s fun, we promise!You are all about collaboration. You’ll be working within ML and Data, and with different teams across Wave. It’s not going to work if you don’t see the value of different perspectivesYou are a stellar communicator. This means you know how to translate technical terms into non-technical language that is easy to understandAt Wave, you’re treated like the incredible human being you are.Work From Where You Work Best: We will always have a welcoming, energizing, and world-class office (in Toronto) with a space for you. Or, if you’re more comfortable working from home, the choice is yours.We Care About Future You: You will stretch yourself and you will grow at Wave. You will also be supported on this journey with diverse learning experiences, educational allowances, mentorship, and so much more.We Support the Full You: We make a serious investment in your health & wellness. When we think about benefits we think about body, mind, & soul and we take this stuff very seriously.We Take Care of the Fundamentals: Fair compensation, all the office perks you’d want, and the various goodies you’d expect from a growing tech company. This is the obvious stuff, but we don’t want you to think we forgot!We believe that a diverse and inclusive culture creates the best workplace. We embrace our differences, value individuality, and the broad spectrum of every Waver's skills and abilities. We challenge each other from a place of respect and pursuit of continuous growth. We trust each other and encourage everyone to bring their authentic selves to work, everyday. As Wavers, our voices matter, our opinions are met with an open mind. The best ideas win, no matter whose they are. Contributing to an inclusive culture is a part of all of our job descriptions.We’ve been continuously recognized as one of Canada's Top Ten Most Admired Corporate Cultures and one of Canada’s Great Places to Work in categories including Technology, Millennials, Mental Health, Inclusion and Women.Are you ready to be a Waver? Join us!\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_test['Job Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engineering with ChatOpenAi api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.1, max_tokens=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "1. Responsibilities:\n",
      "   - Strengthen the scalability, maintainability, and adaptability of the machine learning (ML) practice\n",
      "   - Develop ML models as solutions for functional and product stakeholders\n",
      "   - Collaborate with Agile teams and stakeholders to build and deploy models that address business objectives\n",
      "   - Analyze and engineer features using large amounts of data from multiple sources\n",
      "   - Automate and maintain a system architecture that supports ML at scale\n",
      "\n",
      "2. Requirements:\n",
      "   - 3+ years of experience implementing and maintaining production ML systems\n",
      "   - Strong foundational knowledge in ML and experience with various classification models\n",
      "   - Proficiency in Python, SQL, AWS, Amazon SageMaker, and Docker\n",
      "   - Practical knowledge of MLOps and building pipelines for model training and deployment\n",
      "   - Bonus: experience with natural language processing and large language models\n",
      "\n",
      "3. Company Culture:\n",
      "   - Self-motivated and autonomous work style\n",
      "   - Value collaboration and different perspectives\n",
      "   - Strong communication skills to translate technical terms into non-technical language\n",
      "   - Focus on employee well-being, learning, and growth\n",
      "   - Embrace diversity and inclusion in the workplace\n"
     ]
    }
   ],
   "source": [
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "            template=\"You are summarizing a job description for a chatbot.\\\n",
    "                    Provide a concise summary of the job description in three parts.\\\n",
    "                    Each part has 5 bullet points. Make sure all the skills, technologies are covered.\",\n",
    "            input_variables=[]\n",
    "            )\n",
    ")\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"The following is the job description {jd}?\",\n",
    "            input_variables=[\"jd\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "response_jd_summary = chain.run(job_test['Job Description'])\n",
    "\n",
    "print(response_jd_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Requirements:\n",
      "   - 3+ years of experience implementing and maintaining production ML systems\n",
      "   - Strong foundational knowledge in ML and experience with various classification models\n",
      "   - Proficiency in Python, SQL, AWS, Amazon SageMaker, and Docker\n",
      "   - Practical knowledge of MLOps and building pipelines for model training and deployment\n",
      "   - Bonus: experience with natural language processing and large language models\n"
     ]
    }
   ],
   "source": [
    "print(response_jd_summary.split('\\n\\n')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully matched skills:\n",
      "- Proficiency in Python, SQL, AWS, Amazon SageMaker, and Docker\n",
      "\n",
      "Partial matched skills:\n",
      "- 3+ years of experience implementing and maintaining production ML systems\n",
      "- Strong foundational knowledge in ML and experience with various classification models\n",
      "- Practical knowledge of MLOps and building pipelines for model training and deployment\n",
      "\n",
      "Not matched skills:\n",
      "- Bonus: experience with natural language processing and large language models\n",
      "\n",
      "Note: The provided resume does not explicitly mention experience with ML systems, ML foundational knowledge, MLOps, or NLP.\n"
     ]
    }
   ],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "            template=\"You are comparing the skills listed in a job description with the skills mentioned in a resume. \\\n",
    "                    Categorize skills in the job description skills into 1. Fully matched, 2. Partial matched, 3. Not matched \\\n",
    "                    \",\n",
    "            input_variables=[]\n",
    "            )\n",
    ")\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"Job description skills: {job_skill_required} \\n\\\n",
    "                    Resume {resume} \",\n",
    "            input_variables=['resume','job_skill_required'],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "response = chain.run({'resume': resume_skills_summary, \n",
    "                        'job_skill_required': response_jd_summary.split('\\n\\n')[1]})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.1, max_tokens=3000)\n",
    "\n",
    "def summarize_resume_skills(resume):\n",
    "\n",
    "    prompt_template_resume_skill_summary = PromptTemplate(\n",
    "    input_variables =['resume'],\n",
    "    template = \"List all the skills/ technoolgies mentioned in the follow resume {resume}\"\n",
    ")\n",
    "\n",
    "    name_chain = LLMChain(llm=llm, prompt=prompt_template_resume_skill_summary)\n",
    "\n",
    "    response = name_chain.run(resume)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_skills_summary = summarize_resume_skills(pdftotext_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skills/Technologies: \n",
      "- Self-starter with strong initiative in identifying and solving problems through research, development and testing\n",
      "- Advanced analytical skills\n",
      "- Analytics & Visualization: SQL, Tableau, Power BI, SparkSQL, BigQuery, Azure Synapse, Matplotlib, Seaborn, Plotly\n",
      "- Big Data & Cloud: Spark, Databricks, Azure, AWS, GCP, Terraform\n",
      "- Data Science tools: PyTorch, TensorFlow, scikit-learn, Pandas, NumPy, Spacy, Label Studio, Great Expectations\n",
      "- Programming: Python, SQL (MySQL, PostgreSQL), R, Linux/Bash, Git, Docker, JavaScript, React, Flask\n",
      "- Certification: Azure Data Scientist Associate, AWS Solution Architect Associate\n"
     ]
    }
   ],
   "source": [
    "print(resume_skills_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True: \n",
    "    a = 3\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
